---
layout: post
title: <우리FISA 클라우드 엔지니어링/> Kafka Cluster
subtitle: Kafka Cluster란?
author: 김혁준
categories: 블로그
tags: blog kafka
---

안녕하세요 F4팀의 김혁준입니다. Kafka를 활용한 프로젝트를 구현하면서 Kakfa에 대해 제가 이해한 점을 정리하고 공유하기 위해 글을 작성합니다. 부족한 부분이 있을 수 있으니 가볍게 참고용으로 봐주시길 바랍니다😊
<br><br>

## Multi-Node Kafka
분산 시스템으로서 카프카의 성능과 가용성을 함께 향상시킬 수 있도록 구성<br>
스케일 아웃 기반으로 노드 증설을 통해 카프카의 메시지 전송과 읽기 성능을 거의 선형적으로 증가
데이터 복제를 통해 분산 시스템 기반에서 카프카의 최적 가용성을 보장<br>

분산 시스템은 대량 데이터를 여러 노드간 분산 처리를 통해 빠르게 처리할 수 있는 큰 성능적 이점을 가지지만 안정성과 가용성 측면에서 상대적인 단점을 가집니다.<br>

### 단일 노드
카프카를 단일 노드로 사용한다면 단일 노드에 대해서만 가용성 구성을 강화하면 되므로 매우 안정적인 시스템 구성이 가능하고 소프트웨어에서 다양한 성능 향상 기법을 도입하기 쉽지만
단일 노드에서 처리하려는 데이터가 기하 급수적으로 늘어난다면 scale up 방식으로 증설하기에는 한계가 있습니다.<br>

### 멀티 노드<br>
다수의 노드에서 분산 구성 시 개별 노드를 scale out 방식으로 증설
한 개의 노드에서만 장애가 발생해도 올바른 데이터 처리가 되지 않음
다수의 하드웨어로 구성하므로 빈번한 장애 가능성, 관리 부담 증가
소프트웨어 자체에서 성능, 가용성 처리 제약
==> 데이터 복제를 통해 분산 시스템 기반에서 카프카의 최적 가용성 보장

카프카 리플리케이션 replication
개별 노드의 장애를 대비하여 높은 가용성을 제공
가용성의 핵심은 리블리케이션 (복제)
토픽 생성 시 replication factor 설정값을 통해 구성
reflication factor가 3이면 원본 파티션과 복제 파티션을 포함하여 모두 3개의 파티션을 가짐을 의미
replication factor의 개수는 브로커의 개수보다 클 수 없음
****replication의 동자긍ㄴ 토픽 내의 개별 파티션들을 대상으로적용
***replicationfactor의 대상인 파티션들은 1개의 leader와 n개의 follower로 구성

producer와 consumer는 leader 파티션을 통해서 쓰기와 읽기 수행
파티션의 replication은 leader에서 follwer로만 이뤄짐
파티션 리더를 관리하는 브로커는 producer/consumer의 읽기/쓰기를 관리함과 동시에 파티션 팔로우를 관리하는 브로커의 replication도 관리

단일 파티션일 경우와 멀티 파티션일 경우의 replication 설명 그림 찾기
broker들이 갖는 메타데이터 찾아보기(metadatacache)


Zookeeper : 분산 시스템간의 정보를 신속하게 공유하기 위한 코디네이션 시스템 (분산 시스템 (하둡, 하이브) 등의 로고가 동물이라서 주키퍼)
클러스터 내 개별 노드의 중요한 상태 정보를 관리하며 분산 시스템에서 리더 노드를 선출하는 역할등을 수행
개별 노드간 상태 정보의 동기화를 위한 복잡한 lock관리 기능 제공
간편한 디렉토리 구조 기반의 z Node를 활용 (개별 노드 - (브로커)의 중요 정보를 담고 있음)
개별 노드들은 z Node를 모니터링하며 z node에 변경 발생시 watch event가 트리거되어 변경 정보가 개별 노드들에 통보
zookeeper 자체의 클러스터링 기능 제공

Controller Broker 선출 (선착순)
Controller는 여러 브로커들에서 파티션 리더 선출 수행

클러스터 내 브로커의 멤버쉽 관ㄹ
클러스터의 broker들의 list, broker join/leave 관리 및 통보

토픽 정보


모든 카프카 브로커는 주기적으로 주키퍼에 접속하면서 세션 하트비트를 전송하여 자신의 상태를 보고함
zookeeper.session.timeout.ms 이내에 heartbeat를 받지 못하면 해당 브로커의 노드 정보를 삭제하고 controller 노드에게 변경 사실을 통보
controller노드는 다운된 브로커가 관리하는 파티션들에 대해서 새로운 파티션 leaderElection 수행
다운된 브로커가 controller면 모든 노드에게 해당 사실을 통보하고 가장 먼저 접속한 브로커가 controller가 됨


partition leader broker가 죽으면 리더 바뀜 ㅅㅂ 당연한거 아니야?

isr in-sync-replicas
동기화 되어있는 브로커?라고 생각하면 될듯
follower들은 누구라도 leader가 될 수 있지만 isr 내에 있는 follower들만 가능
파티션의 leader 브로커는 follwer파티션의 브로커들이 leader가 될 수 있는지 지속적으로 모니터링 수행하여 isr을 관리
leader 파티션의 메시지를 follower가 빠르게 복제하지 못하고 뒤쳐질 경우 isr에서 해당 follower는 제거되며 leader가 문제가 생길 때 leader가 될 수 없음

조건
    브로커가 zookeeper에 연결되어 있어야함 zookeeper.session.timeout.ms로 지정된 기간(기본 6초 최대 18초)내에 핥빝을 지속적으로 보내야함
    replica/lag/time/max/ms로 지정된 기간 (기본 10초, max 30초)내에 leader의 메시지를 지속적으로 가져가야함
leader 파티션이 있는 브로커는 follower들이 제대로 데이터를 가져가는지 모니터링 하면서 isr 관리

follower는 leader에게 fetch 요청을 수행, fetch 요청에는 follower가 다음에 읽을 메시지의 offset 번호를 포함
leader는 follower가 요청한 offset 번호와 현재 leader partition의 가장 최신 offset 번호를 비교하여 follower가 얼마나 leader 데이터 복제를 잘 수행하고 있는지 판단

isr에서 벗어난 브로커는 자동으로 다시 isr에 포함될 수 없다! -> 카프카 클러스터의 안정성을 위함
다시 복구시키려면 수동으로 설정 해줘야함
























<hr/>
<br> #우리FIS 아카데미, #우리에프아이에스, #우리FIS Future 핀테크랩, #우리FISA, #클라우드 엔지니어링, #K-Digtal Training
